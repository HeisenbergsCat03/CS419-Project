{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCX_UP12M4RJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxdRGVB0M4RL",
        "outputId": "f069db94-9ecc-4118-a6a9-9426d34ee9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transforms_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Loading the CIFAR-10 dataset:\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf5rF3aDM4RN"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDigDwc6M4RN",
        "outputId": "bc0e1427-9015-4323-daa5-23626510f9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "teacher_model = torchvision.models.resnet18(pretrained=True)\n",
        "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 10)  # Modify the last layer to output 10 classes as CIFAR 10 has 10 classes\n",
        "teacher_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh4vI2ZJM4RO"
      },
      "outputs": [],
      "source": [
        "class LightNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LightNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6vpkxSCM4RP",
        "outputId": "7ed172e9-acbd-46ca-e318-d2deb69619af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LightNN(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "student_model = LightNN()\n",
        "teacher_model.to(device)\n",
        "student_model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-c4gjfUM4RP"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keH9S2qFM4RQ",
        "outputId": "59938b61-1d69-43f2-aab5-08b9f39f2b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8913398543587121\n",
            "Epoch 2/10, Loss: 0.5771907635052186\n",
            "Epoch 3/10, Loss: 0.44804791869867183\n",
            "Epoch 4/10, Loss: 0.3595827208531787\n",
            "Epoch 5/10, Loss: 0.27550305530924324\n",
            "Epoch 6/10, Loss: 0.21650786953204124\n",
            "Epoch 7/10, Loss: 0.17429714370757113\n",
            "Epoch 8/10, Loss: 0.14862033497075292\n",
            "Epoch 9/10, Loss: 0.12260043871639024\n",
            "Epoch 10/10, Loss: 0.10782287292696936\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(12)\n",
        "#test accuracy of teacher model\n",
        "nn_light = LightNN(num_classes=10).to(device)\n",
        "train(teacher_model,train_loader,10,0.001,device)\n",
        "      # Instantiate the lightweight network:\n",
        "torch.manual_seed(12)\n",
        "nn_light = LightNN(num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2obWZbEM4RQ",
        "outputId": "ec80976e-34b1-4c74-8315-e80bb41946f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n"
          ]
        }
      ],
      "source": [
        "test_teacher_acc = test(teacher_model,test_loader,device) # After training the teacher model i.e ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvrAuCaxM4RR",
        "outputId": "fd7596f3-7c12-4d3b-b6bb-1368a19f3e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4839133606542407\n",
            "Epoch 2/10, Loss: 1.1422722562194785\n",
            "Epoch 3/10, Loss: 1.0060766395705436\n",
            "Epoch 4/10, Loss: 0.9065643340120535\n",
            "Epoch 5/10, Loss: 0.8275762406151618\n",
            "Epoch 6/10, Loss: 0.7629977048510481\n",
            "Epoch 7/10, Loss: 0.6959948579368689\n",
            "Epoch 8/10, Loss: 0.6385537817350129\n",
            "Epoch 9/10, Loss: 0.5796255488377398\n",
            "Epoch 10/10, Loss: 0.5325781712141793\n",
            "Test Accuracy: 70.94%\n"
          ]
        }
      ],
      "source": [
        "train(student_model, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_ce = test(student_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aLS6CWSM4RS"
      },
      "outputs": [],
      "source": [
        "new_nn_light = LightNN(num_classes=10).to(device)\n",
        "\n",
        "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    teacher.eval()  # Teacher set to evaluation mode\n",
        "    student.train() # Student to train mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(inputs)\n",
        "\n",
        "            # Forward pass with the student model\n",
        "            student_logits = student(inputs)\n",
        "\n",
        "            #Soften the student logits by applying softmax first and log() second\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
        "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size(0) * (T**2)\n",
        "\n",
        "            # Calculate the true label loss\n",
        "            label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "            # Weighted sum of the two losses\n",
        "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GklTruTnM4RS",
        "outputId": "0fe60bc2-d13b-41cb-e477-0bf6fd65f55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.255328537862929\n",
            "Epoch 2/10, Loss: 1.7522254224933322\n",
            "Epoch 3/10, Loss: 1.547888114324311\n",
            "Epoch 4/10, Loss: 1.3963010968149776\n",
            "Epoch 5/10, Loss: 1.2733512610730613\n",
            "Epoch 6/10, Loss: 1.172116348810513\n",
            "Epoch 7/10, Loss: 1.0820440149977995\n",
            "Epoch 8/10, Loss: 1.005013661463852\n",
            "Epoch 9/10, Loss: 0.931414150063644\n",
            "Epoch 10/10, Loss: 0.8675993246495571\n",
            "Test Accuracy: 71.01%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
        "train_knowledge_distillation(teacher=teacher_model, student=new_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd = test(new_nn_light, test_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compare the student test accuracy with and without the teacher, after distillation\n",
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsCpVA8TRLUv",
        "outputId": "e8d3413f-965d-4f0d-aed5-d0de6efc52c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Student accuracy without teacher: 70.94%\n",
            "Student accuracy with CE + KD: 71.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ8rAuxlM4RT",
        "outputId": "0cd09737-2224-4505-bb57-8ae1c5101ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 267738\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters:\", num_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing a less complex student model"
      ],
      "metadata": {
        "id": "wE4AIA0nUi0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(8 * 8 * 8, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "student_model2 = SimpleNN()\n",
        "student_model2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwLVFXkNUhEM",
        "outputId": "af0b4661-9d90-47a5-d463-1a90e94300d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(p.numel() for p in student_model2.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters:\", num_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ll8u08PUpE1",
        "outputId": "fdb95fe5-55b3-425c-b9de-1fcebf3bde01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 34290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Have reduced the training parameters 8-fold\n"
      ],
      "metadata": {
        "id": "IkuXF4djU4Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(student_model2, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_ce2 = test(student_model, test_loader, device) # have tested the earlier student model here, have tested the newer trained model 2 blocks ahead"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbn9bzw9Ux15",
        "outputId": "31e6895a-d35c-4006-e359-f7102561f39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.6995985050640448\n",
            "Epoch 2/10, Loss: 1.4124027164390935\n",
            "Epoch 3/10, Loss: 1.3158904317089968\n",
            "Epoch 4/10, Loss: 1.2542868084309962\n",
            "Epoch 5/10, Loss: 1.2044663305782601\n",
            "Epoch 6/10, Loss: 1.1705441418511178\n",
            "Epoch 7/10, Loss: 1.1365708762117663\n",
            "Epoch 8/10, Loss: 1.1128534750865244\n",
            "Epoch 9/10, Loss: 1.0901222395165193\n",
            "Epoch 10/10, Loss: 1.0715871628592997\n",
            "Test Accuracy: 70.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn_light2 = SimpleNN(num_classes=10).to(device)\n",
        "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
        "train_knowledge_distillation(teacher=teacher_model, student=new_nn_light2, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd2 = test(new_nn_light2, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-JlVKtZU_Ch",
        "outputId": "64a760b0-0e99-4a00-f3a8-c34f7a93954d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.7138322710686023\n",
            "Epoch 2/10, Loss: 2.219245237462661\n",
            "Epoch 3/10, Loss: 2.0599898176120064\n",
            "Epoch 4/10, Loss: 1.949792299429169\n",
            "Epoch 5/10, Loss: 1.8652809367460363\n",
            "Epoch 6/10, Loss: 1.8011495612771309\n",
            "Epoch 7/10, Loss: 1.7504935206659615\n",
            "Epoch 8/10, Loss: 1.713055707609562\n",
            "Epoch 9/10, Loss: 1.6756213196098346\n",
            "Epoch 10/10, Loss: 1.6412708597719823\n",
            "Test Accuracy: 62.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test(student_model2, test_loader, device):.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd2:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7QqV8EMVkkt",
        "outputId": "eaa36dbe-e039-4c25-9828-3fe2b3ecae56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Test Accuracy: 62.46%\n",
            "Student accuracy without teacher: 62.46%\n",
            "Student accuracy with CE + KD: 62.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with the fractions of CE loss and distillation loss on the earlier student architecture. Originally, the split is 0.75 CE and 0.25 DE"
      ],
      "metadata": {
        "id": "UcCDTQmsWQlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_student_ = LightNN(num_classes=10).to(device)\n",
        "newer_student_ = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "F3CMyRlLWADd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(teacher=teacher_model, student=new_student_, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.5, ce_loss_weight=0.5, device=device)\n",
        "test_accuracy_light_ce_and_kd = test(new_student_, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqDEDOMzWohm",
        "outputId": "e481be08-643f-4776-e79b-4b309ebc82d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 3.064442022987034\n",
            "Epoch 2/10, Loss: 2.3497703560173053\n",
            "Epoch 3/10, Loss: 2.0468436199076034\n",
            "Epoch 4/10, Loss: 1.8678961894701205\n",
            "Epoch 5/10, Loss: 1.706568258192838\n",
            "Epoch 6/10, Loss: 1.5891584795149392\n",
            "Epoch 7/10, Loss: 1.4777253796072567\n",
            "Epoch 8/10, Loss: 1.379095415325116\n",
            "Epoch 9/10, Loss: 1.2905288721289476\n",
            "Epoch 10/10, Loss: 1.2057416649425732\n",
            "Test Accuracy: 70.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE - 0.5 + KD - 0.5: {test_accuracy_light_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ITEniY8W3fV",
        "outputId": "912587a7-cf24-4d9e-f158-47e8a3d851a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Student accuracy without teacher: 70.94%\n",
            "Student accuracy with CE - 0.5 + KD - 0.5: 70.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(teacher=teacher_model, student=newer_student_, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.75, ce_loss_weight=0.25, device=device)\n",
        "test_accuracy_light_ce_and_kd_new = test(newer_student_, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgDPiturXoif",
        "outputId": "952acd43-5a4f-401b-ff54-09bc96c8299f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 3.7721775011028473\n",
            "Epoch 2/10, Loss: 2.8648899132028567\n",
            "Epoch 3/10, Loss: 2.491447638977519\n",
            "Epoch 4/10, Loss: 2.2353563915433177\n",
            "Epoch 5/10, Loss: 2.038106931749817\n",
            "Epoch 6/10, Loss: 1.8922760700020949\n",
            "Epoch 7/10, Loss: 1.7563159075539436\n",
            "Epoch 8/10, Loss: 1.6474022938467352\n",
            "Epoch 9/10, Loss: 1.5314176097855239\n",
            "Epoch 10/10, Loss: 1.448274991701326\n",
            "Test Accuracy: 71.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE - 0.25 + KD - 0.75: {test_accuracy_light_ce_and_kd_new:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjxLtMPlYfnB",
        "outputId": "0b69b86b-7bc0-4f3a-f0af-fee5277107ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Student accuracy without teacher: 70.94%\n",
            "Student accuracy with CE - 0.25 + KD - 0.75: 71.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect of the parameter T. Earlier it was kept = 2"
      ],
      "metadata": {
        "id": "cnq99QIbZTjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new__student = LightNN(num_classes=10).to(device)\n",
        "newer__student = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "kHdmNYPsYyjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(teacher=teacher_model, student=new__student, train_loader=train_loader, epochs=10, learning_rate=0.001, T=1.5, soft_target_loss_weight=0.5, ce_loss_weight=0.5, device=device)\n",
        "test_accuracy_light_ce_and_kd_ = test(new__student, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFUNmGrYZgHp",
        "outputId": "d4c58e0e-ec04-456c-a286-f72990c8ce20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.166744774869641\n",
            "Epoch 2/10, Loss: 1.6616742272511162\n",
            "Epoch 3/10, Loss: 1.460659090820176\n",
            "Epoch 4/10, Loss: 1.3118485248912022\n",
            "Epoch 5/10, Loss: 1.1865622020133622\n",
            "Epoch 6/10, Loss: 1.0955751151075144\n",
            "Epoch 7/10, Loss: 1.0138910421934884\n",
            "Epoch 8/10, Loss: 0.9373732555247939\n",
            "Epoch 9/10, Loss: 0.8705272830050924\n",
            "Epoch 10/10, Loss: 0.8093018786376699\n",
            "Test Accuracy: 70.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD + T = 1.5: {test_accuracy_light_ce_and_kd_:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSDHtUUtbAIe",
        "outputId": "86667c4c-0c95-4443-fa1c-24058b643e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Student accuracy without teacher: 70.94%\n",
            "Student accuracy with CE + KD + T = 1.5: 70.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(teacher=teacher_model, student=newer__student, train_loader=train_loader, epochs=10, learning_rate=0.001, T=1.01, soft_target_loss_weight=0.5, ce_loss_weight=0.5, device=device)\n",
        "test_accuracy_light_ce_and_kd__ = test(newer__student, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yawPAFpwbFO7",
        "outputId": "db71c58d-49ad-460a-a4dc-28b797e36e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: nan\n",
            "Epoch 2/10, Loss: nan\n",
            "Epoch 3/10, Loss: nan\n",
            "Epoch 4/10, Loss: nan\n",
            "Epoch 5/10, Loss: nan\n",
            "Epoch 6/10, Loss: nan\n",
            "Epoch 7/10, Loss: nan\n",
            "Epoch 8/10, Loss: nan\n",
            "Epoch 9/10, Loss: nan\n",
            "Epoch 10/10, Loss: nan\n",
            "Test Accuracy: 70.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test(teacher_model,test_loader,device):.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD + T = 1.01: {test_accuracy_light_ce_and_kd__:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpRLkamPbM9c",
        "outputId": "85e4a6b4-6533-4730-90d3-e72bba6117af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.30%\n",
            "Teacher accuracy: 80.30%\n",
            "Student accuracy without teacher: 70.94%\n",
            "Student accuracy with CE + KD + T = 1.01: 70.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mp-NxKhXbVr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}